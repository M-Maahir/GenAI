{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nStep 1: Identify the intent of the user’s queryExplain about inheritance in python. Is the user asking for documentation, examples, comparisons, or best practices?\\n\\nStep 2: Determine the relevant programming language, framework, or tool from the query.\\n\\nStep 3: Search for the most relevant documentation link or description based on official sources.\\n\\nStep 4: If the user requests an example, provide a concise, beginner-friendly code snippet illustrating the function or concept.\\n\\nStep 5: Format the response in a structured way:\\n\\nDefinition (Brief explanation of the function/module)\\nSyntax (Code signature, parameters, and return values)\\nExample (Minimal working example)\\nLink (Official documentation reference)\\nStep 6: Offer additional guidance by asking: \"Would you like to see related functions or alternative methods?\\n', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 1000}}\n",
      "I'd be happy to help with your request. However, I need a bit more information from you. Please provide me with the following details:\n",
      "\n",
      "1. **Function/Topic**: What function or topic would you like me to document (e.g., a programming concept, scientific term, mathematical formula)?\n",
      "2. **Format**: Would you like the documentation in a specific format (e.g., markdown, reStructuredText, plain text)?\n",
      "\n",
      "Assuming I don't have any further information, here is a sample response for the original prompt:\n",
      "\n",
      "## What is a System?\n",
      "\n",
      "A system is an organized set of components that work together to achieve a common goal or set of goals.\n",
      "\n",
      "### Definition\n",
      "\n",
      "A system consists of input, processing, storage, output, and control mechanisms that interact with each other to produce desired outcomes.\n",
      "\n",
      "### Characteristics\n",
      "\n",
      "Systems can be complex and dynamic, involving various physical, social, or technological elements.\n",
      "\n",
      "### Examples\n",
      "\n",
      "* A computer system\n",
      "* A manufacturing process\n",
      "* A transportation network\n",
      "Time taken: 4.759s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT  PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "\n",
    "MESSAGE = \"Explain about inheritance in python\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "PROMPT = f\"\"\"\n",
    "Step 1: Identify the intent of the user’s query{MESSAGE}. Is the user asking for documentation, examples, comparisons, or best practices?\n",
    "\n",
    "Step 2: Determine the relevant programming language, framework, or tool from the query.\n",
    "\n",
    "Step 3: Search for the most relevant documentation link or description based on official sources.\n",
    "\n",
    "Step 4: If the user requests an example, provide a concise, beginner-friendly code snippet illustrating the function or concept.\n",
    "\n",
    "Step 5: Format the response in a structured way:\n",
    "\n",
    "Definition (Brief explanation of the function/module)\n",
    "Syntax (Code signature, parameters, and return values)\n",
    "Example (Minimal working example)\n",
    "Link (Official documentation reference)\n",
    "Step 6: Offer additional guidance by asking: \"Would you like to see related functions or alternative methods?\n",
    "\"\"\"\n",
    "#\n",
    "\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=1000)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
